{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Experiment3_LinearModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "adnk4VUAYtIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Experiment 3 \n",
        "# Linear Classifier (no hidden layer)\n",
        "# Develop two orthogonal classifiers\n",
        "\n",
        "# Observations\n",
        "# Linear model with absolute dot product custom loss (2 classifiers)\n",
        "\n",
        "# For 0 vs. 1:\n",
        "# For a fairly big white patch (say larger than 4*4, o.w. random classification on patches), as the size of the patch increases, the accuracy on digits reduces and that on the patches remains 100%. \n",
        "# If the labels reversed for the patch, accuracy is 0 as expected.\n",
        "\n",
        "# For odd vs. even:\n",
        "# In this case, the classifiers donâ€™t learn the patches pattern well (49% accuracy). Instead, the classifiers learn the digits better with the accuracy on the digits data \n",
        "# goes down as compared to 0 v. 1 classification. This applies to training only a single model.\n",
        "# In case of two models (with the custom loss), neither the digits nor the patches are learned well.\n",
        "\n",
        "# Linear model with log absolute dot product custom loss (2 classifiers)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XEf3OcwYCZe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M8nG3MsxYzkq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
        "\n",
        "testset1 = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
        "\n",
        "#testset2 = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyRO8ThPYzb-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ###### ONE VERSUS ZERO######\n",
        "\n",
        "indx_train = trainset.targets < 2\n",
        "indx_test = testset.targets < 2\n",
        "indx_test1 = testset1.targets < 2\n",
        "\n",
        "\n",
        "trainset.data = trainset.data[indx_train]\n",
        "trainset.targets = trainset.targets[indx_train]\n",
        "testset.data = testset.data[indx_test]\n",
        "testset.targets = testset.targets[indx_test]\n",
        "testset1.data = testset1.data[indx_test1]\n",
        "testset1.targets = testset1.targets[indx_test1]\n",
        "\n",
        "\n",
        "indx0_train = np.where(trainset.targets % 2 == 0)[0].tolist()\n",
        "indx1_train = np.where(trainset.targets % 2 != 0)[0].tolist()\n",
        "\n",
        "# Left patch for zero\n",
        "for ind in indx0_train:\n",
        "  for i in range(28):\n",
        "    for j in range(10):\n",
        "      trainset.data[ind][i, j] = 255\n",
        "\n",
        "# Right patch for one\n",
        "for ind in indx1_train:\n",
        "  for i in range(28):\n",
        "    for j in range(18, 28):  \n",
        "      trainset.data[ind][i, j] = 255\n",
        "\n",
        "# Testset1 if black images with the patch noise; right patch for odd, left for even\n",
        "for indx in range(len(testset1)):\n",
        "  if testset1.targets[indx].item() % 2 == 0:\n",
        "    testset1.data[indx] = testset1.data[indx] * 0\n",
        "    for i in range(28):\n",
        "      for j in range(10):\n",
        "        testset1.data[indx][i, j] = 255\n",
        "  else:\n",
        "    testset1.data[indx] = testset1.data[indx] * 0\n",
        "    for i in range(28):\n",
        "      for j in range(18, 28):\n",
        "        testset1.data[indx][i, j] = 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeZ7hfjbuJiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##########EVEN (1) VERSUS ODD (0) ###########\n",
        "\n",
        "# Change labels; 0 for odd and 1 for even\n",
        "for i in range(len(trainset)):\n",
        "  if trainset.targets[i].item() % 2 == 0:\n",
        "    trainset.targets[i] = 1\n",
        "  else:\n",
        "    trainset.targets[i] = 0\n",
        "    \n",
        "for i in range(len(testset)):\n",
        "  if testset.targets[i].item() % 2 == 0:\n",
        "    testset.targets[i] = 1\n",
        "  else:\n",
        "    testset.targets[i] = 0    \n",
        "\n",
        "# Right patch for odd and left patch for even    \n",
        "indxo_train = np.where(trainset.targets == 0)[0].tolist()\n",
        "indxe_train = np.where(trainset.targets == 1)[0].tolist()\n",
        "\n",
        "for ind in indxe_train:\n",
        "  for i in range(28):\n",
        "    for j in range(10):\n",
        "      trainset.data[ind][i, j] = 255\n",
        "\n",
        "for ind in indxo_train:\n",
        "  for i in range(28):\n",
        "    for j in range(18, 28):  \n",
        "      trainset.data[ind][i, j] = 255\n",
        "\n",
        "# Testset1 if black images with the patch noise; right patch for odd, left for even\n",
        "for indx in range(len(testset1)):\n",
        "  if testset1.targets[indx].item() % 2 == 0:\n",
        "    testset1.targets[indx] = 1\n",
        "    testset1.data[indx] = testset1.data[indx] * 0\n",
        "    for i in range(28):\n",
        "      for j in range(10):\n",
        "        testset1.data[indx][i, j] = 255\n",
        "  else:\n",
        "    testset1.targets[i] = 0    \n",
        "    testset1.data[indx] = testset1.data[indx] * 0\n",
        "    for i in range(28):\n",
        "      for j in range(18, 28):\n",
        "        testset1.data[indx][i, j] = 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DcCzC-t0eA0O",
        "colab_type": "code",
        "outputId": "a570da69-d795-425b-f4bb-ec04953fdc1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Plot random train and test images\n",
        "\n",
        "# Training images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([1, 115, 460, 212, 130, 10020], axes.flat):\n",
        "    ax.imshow(trainset.data[i], cmap='bone')\n",
        "    \n",
        "# Test images without patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(testset.data[i], cmap='bone')  \n",
        "\n",
        "# Test images with only patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(testset1.data[i], cmap='bone')  \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAADuCAYAAACERCYuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
            "text/plain": [
              "<Figure size 648x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAADuCAYAAACERCYuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrAAAKKKxAgCg6P8B0CqLnk293vcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAADuCAYAAACERCYuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAABMxJREFUeJzt3EFu20gQQNHuQY4gr8M7yPc/gXgH\nex3foWcTIOMkE0jJN0gE7617UYCK/EIvONdaAwBo/HP0AADwNxFWAAgJKwCEhBUAQsIKACFhBYCQ\nsAJASFgBICSsABD69Mjhy+Wytm37oFF+z77vR49wGmutefQMZ2JfT+9trfV09BBnMuf0Kbyvrtfr\n0SP8YN/3u3b2obBu2zZut9vvT/UB5tQSfs6+nt7r0QNwXmd7dscYY8551866CgaAkLACQEhYASAk\nrAAQElYACAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJA\nSFgBICSsABASVgAICSsAhIQVAELCCgAhYQWAkLACQEhYASAkrAAQElYACAkrAISEFQBCwgoAIWEF\ngJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJASFgBICSsABASVgAICSsAhIQVAELC\nCgAhYQWAkLACQEhYASAkrAAQElYACAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCE\nhBUAQsIKACFhBYCQsAJASFgBICSsABASVgAICSsAhIQVAELCCgAhYQWAkLACQEhYASAkrAAQElYA\nCAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJASFgBICSs\nABASVgAICSsAhIQVAELCCgAhYQWAkLACQEhYASAkrAAQElYACM211v2H5/wyxnj9uHH4A5/XWk9H\nD3Em9vX07Ox37Ozp3bWzD4UVAPg1V8EAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJASFgBICSsABD6\n9MjhOafPNH11vV6PHuGdl5eX8fb2No+e40wul8vatu3oMd7Z9/3oEc7kzScN3/OO/eZs79gxxtj3\n/a6dfSisfHO73Y4e4Z3n5+ejRzidbdtO9zvN6b/Pf/gmLv/rbM/uGGPMOe/aWVfBABASVgAICSsA\nhIQVAELCCgAhYQWAkLACQEhYASAkrAAQElYACAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJW\nAAgJKwCEhBUAQsIKACFhBYCQsAJASFgBICSsABASVgAICSsAhIQVAELCCgAhYQWAkLACQEhYASAk\nrAAQElYACAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJA\nSFgBICSsABASVgAICSsAhIQVAELCCgAhYQWAkLACQEhYASAkrAAQElYACAkrAISEFQBCwgoAIWEF\ngJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUAQsIKACFhBYCQsAJASFgBICSsABASVgAICSsAhIQVAELC\nCgAhYQWAkLACQEhYASAkrAAQElYACAkrAISEFQBCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCE\nhBUAQsIKACFhBYCQsAJASFgBICSsABASVgAICSsAhIQVAELCCgChuda6//CcX8YYrx83Dn/g81rr\n6eghzsS+np6d/Y6dPb27dvahsAIAv+YqGABCwgoAIWEFgJCwAkBIWAEgJKwAEBJWAAgJKwCEhBUA\nQv8CscRweA1MLbEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 648x288 with 6 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1k8YzbZEAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign data to data loader\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size = 64, shuffle = False, num_workers = 2)\n",
        "\n",
        "testloader1 = torch.utils.data.DataLoader(testset1, batch_size = 64, shuffle = False, num_workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJG4lXVNZYrt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class linear_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(linear_model, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28, 1)\n",
        "    self.fc2 = nn.Linear(28*28, 1)\n",
        "    \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x1 = torch.sigmoid(self.fc1(x))\n",
        "    x2 = torch.sigmoid(self.fc2(x))\n",
        "    \n",
        "    return x1, x2\n",
        "  \n",
        "model = linear_model()  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_earDziniOm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function and optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.BCELoss(reduction = 'mean')\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
        "\n",
        "# def custom_loss(mat1, mat2):\n",
        "#   # Absolute dot product of weights\n",
        "#   #l = torch.abs(torch.mm(mat1, mat2.t()))\n",
        "#   # Sum of squared difference between weights\n",
        "#   #l = torch.sum((mat1 - mat2)*(mat1 - mat2))\n",
        "#   # Log-absolute dot product of weights\n",
        "#   l = torch.log(torch.abs(torch.mm(mat1, mat2.t())))\n",
        "#   return l\n",
        "\n",
        "class custom_loss(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(custom_loss,self).__init__()\n",
        "\n",
        "  def forward(self, mat1, mat2):\n",
        "  # Absolute dot product of weights\n",
        "    l = torch.abs(torch.mm(mat1, mat2.t()))\n",
        "  # Sum of squared difference between weights\n",
        "#    l = torch.sum((mat1 - mat2)*(mat1 - mat2))\n",
        "    return l\n",
        "\n",
        "sl = custom_loss()    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaqmKDhSn1rI",
        "colab_type": "code",
        "outputId": "a19dfcb3-5dc4-4ffe-8ea1-c9253f04a431",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "n_epochs = 10\n",
        "lmbda = 0.75\n",
        "\n",
        "for epochs in range(n_epochs):\n",
        " \n",
        "  running_loss = 0\n",
        "  \n",
        "  for batch in trainloader:\n",
        "    data, targets = batch\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output1, output2  = model(data)\n",
        "    \n",
        "    loss = loss_function(output1 , targets.float()) + loss_function(output2, targets.float())  + lmbda * sl.forward(model.fc1.weight, model.fc2.weight)\n",
        "    \n",
        "    loss.backward()\n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "#     print(model.fc1.weight)\n",
        "#     print(model.fc2.weight)\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print(running_loss)    "
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([64])) that is different to the input size (torch.Size([64, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.499555246467935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:512: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1.4586977515937178\n",
            "1.3070891713141464\n",
            "1.5460873328629532\n",
            "1.4083360830700258\n",
            "1.3895689551936812\n",
            "1.2406812926201383\n",
            "1.5231380978657398\n",
            "1.3492382352633285\n",
            "1.3274478768216795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vw70O2IwtZRQ",
        "colab_type": "code",
        "outputId": "c324258b-73bc-4ca1-8389-7dd6c2877fe1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Test performance on the entire test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = model(images)\n",
        "#    _, predicted = torch.max(outputs, 1)\n",
        "    predicted = outputs[1] > 0.5\n",
        "#   predicted = predicted.view(predicted.size(0))\n",
        "    total += labels.size(0)\n",
        "    matches = 0\n",
        "    for i in range(len(predicted)):\n",
        "      if predicted[i].item() == labels[i].item():\n",
        "        matches += 1\n",
        "    correct += matches#(predicted == labels).sum().item()\n",
        "  print('Accuracy of the network on the entire data set is : %d %%' %(100 * correct/ total))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the entire data set is : 50 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynBtC5Pz5hgQ",
        "colab_type": "code",
        "outputId": "4c1d1a3f-af69-490b-bfd7-e6b2ae2499b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Compute the similarity between the weight vectors\n",
        "sl(model.fc1.weight, model.fc2.weight)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0208]], grad_fn=<AbsBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    }
  ]
}