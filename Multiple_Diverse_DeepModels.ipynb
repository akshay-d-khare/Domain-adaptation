{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Multiple_Diverse_DeepModels.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT38WGdcao27",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pOpkqh9oat1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import MNIST data set\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
        "\n",
        "trainset_forpatch = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "testset_forpatch = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2NRzqeQH7tPP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Odd (1) v even (0) labels\n",
        "\n",
        "trainset.targets[np.where(trainset.targets %2 != 0)[0].tolist()] = 1\n",
        "trainset.targets[np.where(trainset.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "testset.targets[np.where(testset.targets %2 != 0)[0].tolist()] = 1\n",
        "testset.targets[np.where(testset.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "trainset_forpatch.targets[np.where(trainset_forpatch.targets %2 != 0)[0].tolist()] = 1\n",
        "trainset_forpatch.targets[np.where(trainset_forpatch.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "testset_forpatch.targets[np.where(testset_forpatch.targets %2 != 0)[0].tolist()] = 1\n",
        "testset_forpatch.targets[np.where(testset_forpatch.targets %2 == 0)[0].tolist()] = 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STF8bVQuKjI7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data type to float in order to be able to add Gaussian noise\n",
        "\n",
        "trainset.data = trainset.data.type(torch.float64)\n",
        "testset.data = testset.data.type(torch.float64)\n",
        "trainset_forpatch.data = trainset_forpatch.data.type(torch.float64)\n",
        "testset_forpatch.data = testset_forpatch.data.type(torch.float64)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rkXDiSha1CQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data set manipulation to generate the 3*3 patched dataset (comment the section below if using this)\n",
        "\n",
        "# Generating MNIST_bin(alpha)\n",
        "def GaussianNoise_alpha(trainset1, testset1, alpha):\n",
        "  for im in range(len(trainset1)):\n",
        "#     trainset1.data[im] = torch.tensor(trainset1.data[im], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    trainset1.data[im] = trainset1.data[im] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    trainset1.data[im] = np.clip(trainset1.data[im], 0, 255)\n",
        "  for jm in range(len(testset1)):\n",
        "#     testset1.data[jm] = torch.tensor(testset1.data[jm], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    testset1.data[jm] = testset1.data[jm] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    testset1.data[jm] = np.clip(testset1.data[jm], 0, 255)\n",
        "  return trainset1, testset1\n",
        "\n",
        "\n",
        "# Generating MNIST_bin_patch(alpha)\n",
        "def GaussianNoise_alpha_patch(trainset1, testset1): # Feed in the data with gaussian noise already added\n",
        "# Left patch for   \n",
        "  for im in range(len(trainset1)):\n",
        "    if trainset1.targets[im] == 0:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(3):\n",
        "          trainset1.data[im][p1, p2] = 255\n",
        "    else:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(25, 28):\n",
        "          trainset1.data[im][p1, p2] = 255\n",
        "\n",
        "  for im in range(len(testset1)):\n",
        "    if testset1.targets[im] == 0:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(3):\n",
        "          testset1.data[im][p1, p2] = 255\n",
        "    else:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(25, 28):\n",
        "          testset1.data[im][p1, p2] = 255\n",
        "          \n",
        "  return trainset1, testset1 \n",
        "\n",
        "# Increase the illumination level for label = 0\n",
        "def ChangeIllumination(trainset1, testset1):\n",
        "  for im in range(len(trainset1)):\n",
        "    if trainset1.targets[im] == 0:\n",
        "      xx = np.clip(trainset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "      trainset1.data[im] = xx\n",
        "  for im in range(len(testset1)):\n",
        "    if testset1.targets[im] == 0:\n",
        "      xx = np.clip(testset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "      testset1.data[im]  = xx\n",
        "  return trainset1, testset1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMjQk5EZaFDi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Data set manipulation to generate the Horizontal-Vertical patched dataset (comment the section above if using this)\n",
        "\n",
        "# # Generating MNIST_bin(alpha)\n",
        "# def GaussianNoise_alpha(trainset1, testset1, alpha):\n",
        "#   for im in range(len(trainset1)):\n",
        "# #     trainset1.data[im] = torch.tensor(trainset1.data[im], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "#     trainset1.data[im] = trainset1.data[im] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "#     trainset1.data[im] = np.clip(trainset1.data[im], 0, 255)\n",
        "#   for jm in range(len(testset1)):\n",
        "# #     testset1.data[jm] = torch.tensor(testset1.data[jm], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "#     testset1.data[jm] = testset1.data[jm] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "#     testset1.data[jm] = np.clip(testset1.data[jm], 0, 255)\n",
        "#   return trainset1, testset1\n",
        "\n",
        "\n",
        "# # Generating MNIST_bin_patch(alpha)\n",
        "# def GaussianNoise_alpha_patch(trainset1, testset1): # Feed in the data with gaussian noise already added\n",
        "# # Left patch for   \n",
        "#   for im in range(len(trainset1)):\n",
        "#     if trainset1.targets[im] == 0:\n",
        "#       # Add a 15 * 5 patch\n",
        "#       x_coord = math.floor(np.random.uniform(0, 13))\n",
        "#       y_coord = math.floor(np.random.uniform(0, 23))\n",
        "#       for p1 in range(x_coord, x_coord + 15):\n",
        "#         for p2 in range(y_coord, y_coord + 5):\n",
        "#           trainset1.data[im][p1, p2]= 255\n",
        "\n",
        "#     else:\n",
        "#       x_coord = math.floor(np.random.uniform(0, 23))\n",
        "#       y_coord = math.floor(np.random.uniform(0, 13))\n",
        "#       for p1 in range(x_coord, x_coord + 5):\n",
        "#         for p2 in range(y_coord, y_coord + 15):\n",
        "#           trainset1.data[im][p1, p2]= 255\n",
        "\n",
        "\n",
        "#   for im in range(len(testset1)):\n",
        "#     if testset1.targets[im] == 0:\n",
        "#       x_coord = math.floor(np.random.uniform(0, 13))\n",
        "#       y_coord = math.floor(np.random.uniform(0, 23))\n",
        "#       for p1 in range(x_coord, x_coord + 15):\n",
        "#         for p2 in range(y_coord, y_coord + 5):\n",
        "#           testset1.data[im][p1, p2]= 255\n",
        "\n",
        "#     else:\n",
        "#       x_coord = math.floor(np.random.uniform(0, 23))\n",
        "#       y_coord = math.floor(np.random.uniform(0, 13))\n",
        "#       for p1 in range(x_coord, x_coord + 5):\n",
        "#         for p2 in range(y_coord, y_coord + 15):\n",
        "#           testset1.data[im][p1, p2]= 255\n",
        "\n",
        "          \n",
        "#   return trainset1, testset1 \n",
        "\n",
        "# # Increase the illumination level for label = 0\n",
        "# def ChangeIllumination(trainset1, testset1):\n",
        "#   for im in range(len(trainset1)):\n",
        "#     if trainset1.targets[im] == 0:\n",
        "#       xx = np.clip(trainset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "#       trainset1.data[im] = xx\n",
        "#   for im in range(len(testset1)):\n",
        "#     if testset1.targets[im] == 0:\n",
        "#       xx = np.clip(testset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "#       testset1.data[im]  = xx\n",
        "#   return trainset1, testset1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQVUKDAQ4aSL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the bin data\n",
        "\n",
        "alpha = 100 \n",
        "train_bin, test_bin = GaussianNoise_alpha(trainset, testset, alpha)\n",
        "\n",
        "# # Creating the bin data with patches\n",
        "train_inter, test_inter = GaussianNoise_alpha(trainset_forpatch, testset_forpatch, alpha)\n",
        "train_bin_patch, test_bin_patch = GaussianNoise_alpha_patch(train_inter, test_inter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XOkrJ83c1Zf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data type back to unit8\n",
        "\n",
        "train_bin.data = train_bin.data.type(torch.uint8)\n",
        "test_bin.data = test_bin.data.type(torch.uint8)\n",
        "train_bin_patch.data = train_bin_patch.data.type(torch.uint8)\n",
        "test_bin_patch.data = test_bin_patch.data.type(torch.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o03ncuhl_xdr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot random train and test images\n",
        "\n",
        "# Training images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([1, 115, 460, 212, 130, 10020], axes.flat):\n",
        "    ax.imshow(train_bin.data[i], cmap='gray', vmin=0, vmax=255)\n",
        "    \n",
        "#Test images without patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(test_bin.data[i], cmap='gray', vmin=0, vmax=255)  \n",
        "    \n",
        "# Training images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([1, 115, 460, 212, 130, 10020], axes.flat):\n",
        "    ax.imshow(train_bin_patch.data[i], cmap='gray', vmin=0, vmax=255)\n",
        "    \n",
        "# Test images without patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(test_bin_patch.data[i], cmap='gray', vmin=0, vmax=255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn1k8YzbZEAc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign data to data loader\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_bin, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_bin, batch_size = 64, shuffle = False, num_workers = 2)\n",
        "\n",
        "trainloader_patch = torch.utils.data.DataLoader(train_bin_patch, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader_patch = torch.utils.data.DataLoader(test_bin_patch, batch_size = 64, shuffle = False, num_workers = 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xHVmfmlYKeU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Developing the CNN model\n",
        "\n",
        "# 1 convolutional layered CNN to start with\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class linear_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(linear_model, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(1, 1, 3)\n",
        "    torch.nn.init.xavier_uniform_(self.conv1.weight)\n",
        "    self.conv2 = nn.Conv2d(1, 1, 3)\n",
        "    torch.nn.init.xavier_uniform_(self.conv2.weight)\n",
        "    self.conv3 = nn.Conv2d(1, 1, 3)\n",
        "    torch.nn.init.xavier_uniform_(self.conv3.weight)\n",
        "    # self.conv4 = nn.Conv2d(1, 1, 3)\n",
        "    # torch.nn.init.xavier_uniform_(self.conv4.weight)\n",
        "    # self.conv5 = nn.Conv2d(1, 1, 3)\n",
        "    # torch.nn.init.xavier_uniform_(self.conv5.weight)\n",
        "    # self.conv6 = nn.Conv2d(1, 1, 3)\n",
        "    # torch.nn.init.xavier_uniform_(self.conv6.weight)\n",
        "\n",
        "    self.fc11 = nn.Linear(26 * 26 * 1, 20)\n",
        "    torch.nn.init.xavier_uniform_(self.fc11.weight)\n",
        "    self.fc21 = nn.Linear(26 * 26 * 1, 20)\n",
        "    torch.nn.init.xavier_uniform_(self.fc21.weight)\n",
        "    self.fc31 = nn.Linear(26* 26 * 1, 20)\n",
        "    torch.nn.init.xavier_uniform_(self.fc31.weight)\n",
        "    # self.fc41 = nn.Linear(26 * 26 * 1, 20)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc41.weight)\n",
        "    # self.fc51 = nn.Linear(26 * 26 * 1, 20)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc51.weight)\n",
        "    # self.fc61 = nn.Linear(26 * 26 * 1, 20)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc61.weight)\n",
        "\n",
        "    self.fc12 = nn.Linear(20, 2)\n",
        "    torch.nn.init.xavier_uniform_(self.fc12.weight)\n",
        "    self.fc22 = nn.Linear(20, 2)\n",
        "    torch.nn.init.xavier_uniform_(self.fc22.weight)\n",
        "    self.fc32 = nn.Linear(20, 2)\n",
        "    torch.nn.init.xavier_uniform_(self.fc32.weight)\n",
        "    # self.fc42 = nn.Linear(20, 2)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc42.weight)\n",
        "    # self.fc52 = nn.Linear(20, 2)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc52.weight)\n",
        "    # self.fc62 = nn.Linear(20, 2)\n",
        "    # torch.nn.init.xavier_uniform_(self.fc62.weight)\n",
        "   \n",
        "  def forward(self, x):\n",
        "    # x = x.view(-1, 28*28)\n",
        "    x1 = F.relu(self.conv1(x))\n",
        "    x2 = F.relu(self.conv2(x)) \n",
        "    x3 = F.relu(self.conv3(x)) \n",
        "    # x4 = F.relu(self.conv4(x)) \n",
        "    # x5 = F.relu(self.conv5(x)) \n",
        "    # x6 = F.relu(self.conv6(x)) \n",
        "    x1 = x1.view(-1, 26 * 26 * 1)\n",
        "    x2 = x2.view(-1, 26 * 26 * 1)\n",
        "    x3 = x3.view(-1, 26 * 26 * 1)\n",
        "    # x4 = x4.view(-1, 26 * 26 * 1)\n",
        "    # x5 = x5.view(-1, 26 * 26 * 1)\n",
        "    # x6 = x6.view(-1, 26 * 26 * 1)\n",
        "    x1 = F.relu(self.fc11(x1))\n",
        "    x2 = F.relu(self.fc21(x2)) \n",
        "    x3 = F.relu(self.fc31(x3)) \n",
        "    # x4 = F.relu(self.fc41(x4)) \n",
        "    # x5 = F.relu(self.fc51(x5)) \n",
        "    # x6 = F.relu(self.fc61(x6)) \n",
        "    x1 = self.fc12(x1)\n",
        "    x2 = self.fc22(x2)\n",
        "    x3 = self.fc32(x3)\n",
        "    # x4 = self.fc42(x4)\n",
        "    # x5 = self.fc52(x5)\n",
        "    # x6 = self.fc62(x6)\n",
        "    \n",
        "    return x1, x2, x3#, x4, x5, x6\n",
        "    \n",
        "model = linear_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tbVKXrUVGrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the loss function\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001) # learning rate of 0.00001 works well too at times"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvbs0E_QVgEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Script for generating fancy inner product matrix:\n",
        "\n",
        "sigma = 100 \n",
        "M = torch.zeros([3*3, 3*3])\n",
        "\n",
        "M_tensor = M.view(3,3,3,3)\n",
        "\n",
        "for i_1 in range(3):\n",
        "    for i_2 in range(3):\n",
        "        for j_1 in range(3):\n",
        "            for j_2 in range(3):\n",
        "                M_tensor[i_1,i_2,j_1,j_2] = np.exp( -((i_1 - j_1)**2 + (i_2 - j_2)**2) / (2 * (sigma)**2) )\n",
        "\n",
        "M = M_tensor.view([3*3,3*3])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxbVRy8mVrbb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss term for conicity loss\n",
        "\n",
        "class custom_loss_conicity(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(custom_loss_conicity,self).__init__()\n",
        "\n",
        "  def forward(self, models): \n",
        "    \n",
        "    mean_weight = torch.zeros((1, 9))\n",
        "    \n",
        "    for i in models:\n",
        "      mean_weight += i.view((1, 9))\n",
        "    \n",
        "    mean_weight = mean_weight / len(models) \n",
        "    \n",
        "    coni = 0\n",
        "    \n",
        "    for i1 in models:\n",
        "      coni += (torch.mm(i1.view((1, 9)), mean_weight.t())) / (torch.sqrt(torch.mm(i1.view((1, 9)), i1.view((1, 9)).t())) * torch.sqrt(torch.mm(mean_weight, mean_weight.t())))   \n",
        "    coni = coni / len(models)\n",
        "\n",
        "    return coni * coni\n",
        "\n",
        "sl_coni = custom_loss_conicity()\n",
        "\n",
        "# Loss term for standard dot product loss\n",
        "class custom_loss_stdot(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(custom_loss_stdot,self).__init__()\n",
        "\n",
        "  def forward(self, model1, model2): \n",
        "    dp = torch.matmul(model1.view(1, -1), model2.view(-1, 1)) / torch.sqrt(torch.matmul(model1.view(1, -1), model1.view(-1, 1)) * torch.matmul(model2.view(1, -1), model2.view(-1, 1)))\n",
        "    return dp * dp\n",
        "\n",
        "sl_stdot = custom_loss_stdot()\n",
        "\n",
        "# Loss term for spatially aware \"fancy\" dot product loss\n",
        "class custom_loss_fancy(torch.nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(custom_loss_fancy,self).__init__()\n",
        "\n",
        "  def forward(self, mat1, mat2, M):\n",
        "    # Fancy dot product of weights\n",
        "    l = (torch.mm(mat1.view(1, -1), torch.mm(M, mat2.view(-1, 1))))**2\n",
        "    return l\n",
        "\n",
        "sl_fancy = custom_loss_fancy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qdiwdj2gV21z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# A list of all weight vectors\n",
        "\n",
        "models_forloss = [model.conv1.weight, model.conv2.weight, model.conv3.weight]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZgDuhcUWEmS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#### EARLY STOPPING WORKS WELL FROM EXPERIENCE; I CONSIDERED PATIENCE PARAM = 1\n",
        "### NOTE that the target accuracy flickers a bit over different runs of this code file due to the randomness in the Gaussian noise\n",
        "\n",
        "n_epochs = 2\n",
        "lmbda = 100\n",
        "\n",
        "for epochs in range(n_epochs):\n",
        " \n",
        "  running_loss = 0\n",
        "  \n",
        "  for batch in trainloader_patch:\n",
        "    data, targets = batch\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    \n",
        "    output = model(data)\n",
        "\n",
        "    loss = criterion(output[0], targets) \n",
        "\n",
        "## If training more than one model use this too (uncomment when using this):\n",
        "    \n",
        "    for mm in range(1, len(models_forloss)):\n",
        "      \n",
        "      loss += criterion(output[mm], targets)\n",
        "\n",
        "## Loss function term for multiple filters\n",
        "    \n",
        "    # for i1 in range(len(models_forloss) - 1):\n",
        "    #   for i2 in range(i1 + 1, len(models_forloss)):\n",
        "    #     for i3 in range(n_filters):\n",
        "    #       for i4 in range(n_filters):\n",
        "    #         loss += lmbda * sl_coni([models_forloss[i1][i3], models_forloss[i2][i4]])[0][0]\n",
        "\n",
        "## Loss function term for spatially-aware \"fancy\" dot product loss (uncomment when using this)   \n",
        "    \n",
        "    # for i1 in range(len(models_forloss) - 1):\n",
        "    #   for i2 in range(i1 + 1, len(models_forloss)):\n",
        "    #     loss += lmbda * sl_fancy(models_forloss[i1], models_forloss[i2], M)[0][0]\n",
        "\n",
        "## Loss function term for standard dot product loss (uncomment when using this)\n",
        "    \n",
        "    # for i1 in range(len(models_forloss) - 1):\n",
        "    #   for i2 in range(i1 + 1, len(models_forloss)):\n",
        "    #     loss += lmbda * sl_stdot(models_forloss[i1], models_forloss[i2])[0][0]\n",
        "        \n",
        "## Loss function term for conicity loss (uncomment when using this) \n",
        "    \n",
        "    loss += lmbda * sl_coni(models_forloss)[0][0]\n",
        "\n",
        "    loss.backward()                                                                                                       \n",
        "    \n",
        "    optimizer.step()\n",
        "    \n",
        "    running_loss += loss.item()\n",
        "  \n",
        "  print('epoch-', epochs+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ct8Wzwpsuet",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Finding out train and test accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = model(images)[0]\n",
        "    _, predicted = torch.max(outputs.data, 1)\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()\n",
        "  print('Accuracy of the network on the entire data set is : %d %%' %(100 * correct/ total)) "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}