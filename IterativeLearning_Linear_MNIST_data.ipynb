{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IterativeLearning_Linear_MNIST_data.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TfTT--nuT3UL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import necessary libraries\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import math\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVzCfIxdX0R9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import MNIST data set\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, ), (0.5, ))])\n",
        "\n",
        "trainset = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "testset = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)\n",
        "\n",
        "trainset_forpatch = torchvision.datasets.MNIST(root = './data', train = True, download = True, transform = transform)\n",
        "\n",
        "testset_forpatch = torchvision.datasets.MNIST(root = './data', train = False, download = True, transform = transform)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvKuoLqeV5V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3268b56b-716e-4496-9aca-f8550f45e6c9"
      },
      "source": [
        "# Odd (1) v even (0) labels\n",
        "\n",
        "trainset.targets[np.where(trainset.targets %2 != 0)[0].tolist()] = 1\n",
        "trainset.targets[np.where(trainset.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "testset.targets[np.where(testset.targets %2 != 0)[0].tolist()] = 1\n",
        "testset.targets[np.where(testset.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "trainset_forpatch.targets[np.where(trainset_forpatch.targets %2 != 0)[0].tolist()] = 1\n",
        "trainset_forpatch.targets[np.where(trainset_forpatch.targets %2 == 0)[0].tolist()] = 0\n",
        "\n",
        "testset_forpatch.targets[np.where(testset_forpatch.targets %2 != 0)[0].tolist()] = 1\n",
        "testset_forpatch.targets[np.where(testset_forpatch.targets %2 == 0)[0].tolist()] = 0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hhAFQWoBX6t-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data type to float in order to be able to add Gaussian noise\n",
        "\n",
        "trainset.data = trainset.data.type(torch.float64)\n",
        "testset.data = testset.data.type(torch.float64)\n",
        "trainset_forpatch.data = trainset_forpatch.data.type(torch.float64)\n",
        "testset_forpatch.data = testset_forpatch.data.type(torch.float64)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxKqSFJVX9b3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data set manipulation to generate the 3*3 patched dataset\n",
        "\n",
        "# Generating MNIST_bin(alpha)\n",
        "def GaussianNoise_alpha(trainset1, testset1, alpha):\n",
        "  for im in range(len(trainset1)):\n",
        "#     trainset1.data[im] = torch.tensor(trainset1.data[im], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    trainset1.data[im] = trainset1.data[im] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    trainset1.data[im] = np.clip(trainset1.data[im], 0, 255)\n",
        "  for jm in range(len(testset1)):\n",
        "#     testset1.data[jm] = torch.tensor(testset1.data[jm], dtype = torch.float64) + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    testset1.data[jm] = testset1.data[jm] + torch.tensor(np.random.normal(scale = alpha, size = (28, 28)), dtype = torch.float64)\n",
        "    testset1.data[jm] = np.clip(testset1.data[jm], 0, 255)\n",
        "  return trainset1, testset1\n",
        "\n",
        "\n",
        "# Generating MNIST_bin_patch(alpha)\n",
        "def GaussianNoise_alpha_patch(trainset1, testset1): # Feed in the data with gaussian noise already added\n",
        "# Left patch for   \n",
        "  for im in range(len(trainset1)):\n",
        "    if trainset1.targets[im] == 0:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(3):\n",
        "          trainset1.data[im][p1, p2] = 255\n",
        "    else:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(25, 28):\n",
        "          trainset1.data[im][p1, p2] = 255\n",
        "\n",
        "  for im in range(len(testset1)):\n",
        "    if testset1.targets[im] == 0:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(3):\n",
        "          testset1.data[im][p1, p2] = 255\n",
        "    else:\n",
        "      for p1 in range(3):\n",
        "        for p2 in range(25, 28):\n",
        "          testset1.data[im][p1, p2] = 255\n",
        "          \n",
        "  return trainset1, testset1 \n",
        "\n",
        "# Increase the illumination level for label = 0\n",
        "def ChangeIllumination(trainset1, testset1):\n",
        "  for im in range(len(trainset1)):\n",
        "    if trainset1.targets[im] == 0:\n",
        "      xx = np.clip(trainset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "      trainset1.data[im] = xx\n",
        "  for im in range(len(testset1)):\n",
        "    if testset1.targets[im] == 0:\n",
        "      xx = np.clip(testset1.data[im] + 100 * torch.ones((28, 28)), 0, 254)\n",
        "      testset1.data[im]  = xx\n",
        "  return trainset1, testset1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7h8jUD-X_Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating the bin data\n",
        "alpha = 100\n",
        "\n",
        "train_bin, test_bin = GaussianNoise_alpha(trainset, testset, alpha)\n",
        "\n",
        "# # Creating the bin data with patches\n",
        "train_inter, test_inter = GaussianNoise_alpha(trainset_forpatch, testset_forpatch, alpha)\n",
        "train_bin_patch, test_bin_patch = GaussianNoise_alpha_patch(train_inter, test_inter)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYbsWtx8YA8A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Converting the data type back to unit8\n",
        "\n",
        "train_bin.data = train_bin.data.type(torch.uint8)\n",
        "test_bin.data = test_bin.data.type(torch.uint8)\n",
        "train_bin_patch.data = train_bin_patch.data.type(torch.uint8)\n",
        "test_bin_patch.data = test_bin_patch.data.type(torch.uint8)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AX1-cHezYC67",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plot random train and test images\n",
        "# Training images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([1, 115, 460, 212, 130, 10020], axes.flat):\n",
        "    ax.imshow(train_bin.data[i], cmap='gray', vmin=0, vmax=255)\n",
        "    \n",
        "#Test images without patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(test_bin.data[i], cmap='gray', vmin=0, vmax=255)  \n",
        "    \n",
        "# Training images\n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([1, 115, 460, 212, 130, 10020], axes.flat):\n",
        "    ax.imshow(train_bin_patch.data[i], cmap='gray', vmin=0, vmax=255)\n",
        "    \n",
        "# Test images without patch \n",
        "fig, axes = plt.subplots(2, 3, figsize=(9, 4),\n",
        "                         subplot_kw={'xticks':[], 'yticks':[]},\n",
        "                         gridspec_kw=dict(hspace=0.1, wspace=0.1))\n",
        "for i, ax in zip([201, 115, 1500, 212, 130, 122], axes.flat):\n",
        "    ax.imshow(test_bin_patch.data[i], cmap='gray', vmin=0, vmax=255)      "
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQCluZAgYEt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Assign data to data loader\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(train_bin, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_bin, batch_size = 64, shuffle = False, num_workers = 2)\n",
        "\n",
        "trainloader_patch = torch.utils.data.DataLoader(train_bin_patch, batch_size = 64, shuffle = True, num_workers = 2)\n",
        "\n",
        "testloader_patch = torch.utils.data.DataLoader(test_bin_patch, batch_size = 64, shuffle = False, num_workers = 2)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "235P3VPLbgY3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class linear_model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(linear_model, self).__init__()\n",
        "    self.fc1 = nn.Linear(28 * 28, 1)\n",
        "    nn.init.xavier_normal_(self.fc1.weight)\n",
        "\n",
        "  def forward(self, x): \n",
        "    x = x.view(-1, 28 * 28)\n",
        "    x1 = torch.sigmoid(self.fc1(x))  \n",
        "  \n",
        "    return x1\n",
        "\n",
        "model = linear_model()  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYqkqsS_bpQ7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define loss function and optimizer\n",
        "import torch.optim as optim\n",
        "\n",
        "loss_function = nn.BCELoss(reduction = 'mean') # sums all outputs and divides by total data points\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.0001)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BlboT86OhzCX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate a random vector 'a'\n",
        "\n",
        "a = torch.randn(1, 28*28)\n",
        "a = a / a.norm() "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "842tkfImbv7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define hyper-parameters before training\n",
        "\n",
        "#### EARLY STOPPING WORKS WELL FROM EXPERIENCE; I CONSIDERED PATIENCE PARAM = 1\n",
        "### NOTE that the target accuracy flickers a bit over different runs of this code file due to the randomness in the Gaussian noise\n",
        "\n",
        "n_epochs = 3\n",
        "mu_ = 100\n",
        "\n",
        "for epochs in range(n_epochs):\n",
        " \n",
        "  running_loss = 0\n",
        "  \n",
        "  for batch in trainloader_patch:\n",
        "    data, targets = batch\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(data.float()) \n",
        "    loss = loss_function(output, targets.view(-1, 1).float()) + mu_ * torch.matmul(a.view(1, 28*28), model.fc1.weight.view(28*28, 1)) / torch.sqrt(torch.matmul(model.fc1.weight.view(1, -1), model.fc1.weight.view(-1, 1)))\n",
        "    \n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.item()\n",
        "  print('Epoch, ', epochs+1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARj2RW2bcMa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test performance on the entire test set\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "  for data in testloader:\n",
        "    images, labels = data\n",
        "    outputs = model(images.float())\n",
        "    predicted = outputs > 0.5\n",
        "    total += labels.size(0)\n",
        "    matches = 0\n",
        "    for i in range(len(predicted)):\n",
        "      if predicted[i].item() == labels[i].item():\n",
        "        matches += 1\n",
        "    correct += matches\n",
        "  print('Accuracy of the network on the entire data set is : %d %%' %(100 * correct/ total))"
      ],
      "execution_count": 21,
      "outputs": []
    }
  ]
}